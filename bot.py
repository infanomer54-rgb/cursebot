import os
import logging
import sqlite3
import re
import asyncio
from datetime import datetime
import json
import io

import requests
import PyPDF2
import docx2txt
import aiofiles

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application, CommandHandler, MessageHandler, CallbackQueryHandler,
    ContextTypes, filters
)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = os.getenv('BOT_TOKEN')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
os.makedirs("–º–µ—Ç–æ–¥–∏—á–∫–∏", exist_ok=True)
os.makedirs("—Ä–∞–±–æ—Ç—ã", exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

class Database:
    def __init__(self, db_path="bot_database.db"):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS users (
                user_id INTEGER PRIMARY KEY,
                username TEXT,
                first_name TEXT,
                last_name TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS works (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id INTEGER,
                work_type TEXT,
                topic TEXT,
                subject TEXT,
                structure TEXT,
                content TEXT,
                methodic_info TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS methodics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT,
                file_path TEXT,
                requirements TEXT,
                structure TEXT,
                formatting TEXT,
                uploaded_by INTEGER,
                uploaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def add_user(self, user_id, username, first_name, last_name):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT OR REPLACE INTO users (user_id, username, first_name, last_name)
            VALUES (?, ?, ?, ?)
        ''', (user_id, username, first_name, last_name))
        conn.commit()
        conn.close()
    
    def create_work(self, user_id, work_type, topic, subject, methodic_info=None):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        methodic_json = json.dumps(methodic_info) if methodic_info else None
        cursor.execute('''
            INSERT INTO works (user_id, work_type, topic, subject, methodic_info)
            VALUES (?, ?, ?, ?, ?)
        ''', (user_id, work_type, topic, subject, methodic_json))
        work_id = cursor.lastrowid
        conn.commit()
        conn.close()
        return work_id
    
    def update_work_content(self, work_id, content):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('UPDATE works SET content = ? WHERE id = ?', (content, work_id))
        conn.commit()
        conn.close()
    
    def add_methodic(self, filename, file_path, requirements, structure, formatting, user_id):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('''
            INSERT INTO methodics (filename, file_path, requirements, structure, formatting, uploaded_by)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (filename, file_path, requirements, structure, formatting, user_id))
        methodic_id = cursor.lastrowid
        conn.commit()
        conn.close()
        return methodic_id
    
    def get_methodics(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT id, filename FROM methodics ORDER BY uploaded_at DESC')
        methodics = cursor.fetchall()
        conn.close()
        return methodics
    
    def get_methodic(self, methodic_id):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute('SELECT * FROM methodics WHERE id = ?', (methodic_id,))
        result = cursor.fetchone()
        conn.close()
        return result

class DocumentProcessor:
    def extract_text_from_pdf(self, file_path):
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                return text.strip()
        except Exception as e:
            logger.error(f"PDF error: {e}")
            return ""
    
    def extract_text_from_docx(self, file_path):
        try:
            text = docx2txt.process(file_path)
            return text.strip() if text else ""
        except Exception as e:
            logger.error(f"DOCX error: {e}")
            return ""
    
    async def extract_text_from_txt(self, file_path):
        try:
            async with aiofiles.open(file_path, 'r', encoding='utf-8') as file:
                return await file.read()
        except Exception as e:
            logger.error(f"TXT error: {e}")
            return ""
    
    async def process_methodic(self, file_path):
        file_extension = file_path.lower().split('.')[-1]
        text = ""
        
        if file_extension == 'pdf':
            text = self.extract_text_from_pdf(file_path)
        elif file_extension == 'docx':
            text = self.extract_text_from_docx(file_path)
        elif file_extension == 'txt':
            text = await self.extract_text_from_txt(file_path)
        else:
            return None
        
        if not text:
            return None
        
        return self.extract_methodic_info(text)
    
    def extract_methodic_info(self, text):
        requirements = self._extract_requirements(text)
        structure = self._extract_structure(text)
        
        return {
            'requirements': requirements,
            'structure': structure,
            'full_text': text[:4000]
        }
    
    def _extract_requirements(self, text):
        patterns = {
            'volume': r'–æ–±—ä–µ–º[:\s]*([^\n]+)',
            'pages': r'—Å—Ç—Ä–∞–Ω–∏—Ü[:\s]*(\d+)',
            'deadline': r'—Å—Ä–æ–∫[:\s]*([^\n]+)',
            'sections_count': r'—Ä–∞–∑–¥–µ–ª[–æ–≤]*[:\s]*(\d+)',
            'font': r'—à—Ä–∏—Ñ—Ç[:\s]*([^\n]+)',
            'spacing': r'–∏–Ω—Ç–µ—Ä–≤–∞–ª[:\s]*([^\n]+)',
            'margins': r'–ø–æ–ª—è[:\s]*([^\n]+)'
        }
        
        requirements = {}
        for key, pattern in patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                requirements[key] = matches[0] if key in ['pages', 'sections_count'] else matches
        
        return requirements
    
    def _extract_structure(self, text):
        patterns = {
            'sections': r'—Å—Ç—Ä—É–∫—Ç—É—Ä[–∞-—è—ë]*[:\s]*([^\n]+)',
            'introduction': r'–≤–≤–µ–¥–µ–Ω[–∞-—è—ë]*[:\s]*([^\n]+)',
            'chapters': r'–≥–ª–∞–≤–∞|—Ä–∞–∑–¥–µ–ª[:\s]*([^\n]+)',
            'conclusion': r'–∑–∞–∫–ª—é—á–µ–Ω[–∞-—è—ë]*[:\s]*([^\n]+)',
            'bibliography': r'–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä[–∞-—è—ë]*[:\s]*([^\n]+)'
        }
        
        structure_info = {}
        for key, pattern in patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                structure_info[key] = matches
        
        return structure_info

class TextDocumentGenerator:
    def create_document(self, work_type, topic, subject, content, methodic_info, user_info=None):
        """–°–æ–∑–¥–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        try:
            # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            clean_content = self._clean_content(content)
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            document_text = self._create_document_structure(work_type, topic, subject, clean_content, user_info)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ bytes –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            file_stream = io.BytesIO()
            file_stream.write(document_text.encode('utf-8'))
            file_stream.seek(0)
            
            return file_stream
            
        except Exception as e:
            logger.error(f"Error creating text document: {e}")
            return None
    
    def _clean_content(self, content):
        """–û—á–∏—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
        clean = re.sub(r'<[^>]+>', '', content)
        # –£–±–∏—Ä–∞–µ–º –º–∞—Ä–∫–¥–∞—É–Ω —Å–∏–º–≤–æ–ª—ã
        clean = re.sub(r'[*_~`#]', '', clean)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        clean = re.sub(r'\n\s*\n', '\n\n', clean)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        clean = re.sub(r' +', ' ', clean)
        # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã
        clean = re.sub(r'[‚û§‚Ä¢‚ñ™‚ñ∂]', '', clean)
        return clean.strip()
    
    def _create_document_structure(self, work_type, topic, subject, content, user_info):
        """–°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
        
        work_type_names = {
            "coursework": "–ö–£–†–°–û–í–ê–Ø –†–ê–ë–û–¢–ê",
            "essay": "–†–ï–§–ï–†–ê–¢",
            "thesis": "–î–ò–ü–õ–û–ú–ù–ê–Ø –†–ê–ë–û–¢–ê"
        }
        
        title = work_type_names.get(work_type, "–ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–ê–Ø –†–ê–ë–û–¢–ê")
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        document_lines = []
        
        # –¢–∏—Ç—É–ª—å–Ω—ã–π –ª–∏—Å—Ç
        document_lines.append(" " * 20 + "=" * 40)
        document_lines.append(" " * 30 + title)
        document_lines.append("")
        document_lines.append(" " * 25 + f"–ø–æ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω–µ: {subject}")
        document_lines.append("")
        document_lines.append(" " * 20 + f'–Ω–∞ —Ç–µ–º—É: "{topic}"')
        document_lines.append("")
        if user_info:
            document_lines.append(" " * 25 + f"–í—ã–ø–æ–ª–Ω–∏–ª(–∞): {user_info}")
        document_lines.append("")
        document_lines.append(" " * 35 + f"{datetime.now().year} –≥.")
        document_lines.append(" " * 20 + "=" * 40)
        document_lines.append("\n" * 5)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç (—É–∂–µ –æ—á–∏—â–µ–Ω–Ω—ã–π)
        document_lines.append(content)
        
        return "\n".join(document_lines)

class AcademicWriter:
    def __init__(self):
        self.api_key = DEEPSEEK_API_KEY
        self.api_url = DEEPSEEK_API_URL
    
    def generate_complete_work(self, work_type, topic, subject, methodic_info=None):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ä–∞–±–æ—Ç—É —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º"""
        
        work_type_names = {
            "coursework": "–∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã",
            "essay": "—Ä–µ—Ñ–µ—Ä–∞—Ç–∞", 
            "thesis": "–¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã"
        }
        
        # –°–æ–∑–¥–∞–µ–º –æ—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = self._create_detailed_system_prompt(work_type, topic, subject, methodic_info)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        work_parts = []
        
        # –ß–∞—Å—Ç—å 1: –í–≤–µ–¥–µ–Ω–∏–µ
        intro_prompt = f"""
–ù–∞–ø–∏—à–∏ –í–í–ï–î–ï–ù–ò–ï –¥–ª—è {work_type_names[work_type]} –Ω–∞ —Ç–µ–º—É "{topic}" –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

–í–≤–µ–¥–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
1. –ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–º—ã - –ø–æ—á–µ–º—É —ç—Ç–∞ —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ –≤ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
2. –¶–µ–ª—å —Ä–∞–±–æ—Ç—ã - –∫–∞–∫—É—é –≥–ª–∞–≤–Ω—É—é —Ü–µ–ª—å –ø—Ä–µ—Å–ª–µ–¥—É–µ—Ç —Ä–∞–±–æ—Ç–∞
3. –ó–∞–¥–∞—á–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–∏
4. –û–±—ä–µ–∫—Ç –∏ –ø—Ä–µ–¥–º–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
5. –ú–µ—Ç–æ–¥—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
6. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å

–û–±—ä–µ–º: {self._get_section_volume(work_type, '–≤–≤–µ–¥–µ–Ω–∏–µ')}
–°—Ç–∏–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π
"""
        intro = self._make_api_call(system_prompt, intro_prompt)
        if not intro.startswith("‚ùå"):
            work_parts.append(f"–í–í–ï–î–ï–ù–ò–ï\n\n{intro}\n")
        
        # –ß–∞—Å—Ç—å 2: –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å
        main_part_prompt = f"""
–ù–∞–ø–∏—à–∏ –û–°–ù–û–í–ù–£–Æ –ß–ê–°–¢–¨ –¥–ª—è {work_type_names[work_type]} –Ω–∞ —Ç–µ–º—É "{topic}" –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

–û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –≤–∫–ª—é—á–∞—Ç—å:
–ì–õ–ê–í–ê 1. –¢–ï–û–†–ï–¢–ò–ß–ï–°–ö–ò–ï –û–°–ù–û–í–´ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø
- –ê–Ω–∞–ª–∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø–æ —Ç–µ–º–µ
- –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –∏ –ø–æ–¥—Ö–æ–¥—ã
- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–Ω—è—Ç–∏–π

–ì–õ–ê–í–ê 2. –ü–†–ê–ö–¢–ò–ß–ï–°–ö–û–ï –ò–°–°–õ–ï–î–û–í–ê–ù–ò–ï
- –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –ø—Ä–∏–º–µ—Ä–æ–≤
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

–ì–õ–ê–í–ê 3. –ê–ù–ê–õ–ò–ó –ò –í–´–í–û–î–´
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è–º–∏
- –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –≤—ã–≤–æ–¥—ã

–û–±—ä–µ–º: {self._get_section_volume(work_type, '–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å')}
–°—Ç–∏–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –∞–Ω–∞–ª–∏–∑–æ–º
"""
        main_part = self._make_api_call(system_prompt, main_part_prompt)
        if not main_part.startswith("‚ùå"):
            work_parts.append(f"–û–°–ù–û–í–ù–ê–Ø –ß–ê–°–¢–¨\n\n{main_part}\n")
        
        # –ß–∞—Å—Ç—å 3: –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
        conclusion_prompt = f"""
–ù–∞–ø–∏—à–∏ –ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï –¥–ª—è {work_type_names[work_type]} –Ω–∞ —Ç–µ–º—É "{topic}" –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

–ó–∞–∫–ª—é—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
1. –û—Å–Ω–æ–≤–Ω—ã–µ –≤—ã–≤–æ–¥—ã –ø–æ —Ä–∞–±–æ—Ç–µ
2. –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ª–∏ —Ü–µ–ª—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
3. –†–µ—à–µ–Ω—ã –ª–∏ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏
4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã
5. –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–û–±—ä–µ–º: {self._get_section_volume(work_type, '–∑–∞–∫–ª—é—á–µ–Ω–∏–µ')}
–°—Ç–∏–ª—å: –∏—Ç–æ–≥–æ–≤—ã–π, —Å —á–µ—Ç–∫–∏–º–∏ –≤—ã–≤–æ–¥–∞–º–∏
"""
        conclusion = self._make_api_call(system_prompt, conclusion_prompt)
        if not conclusion.startswith("‚ùå"):
            work_parts.append(f"–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï\n\n{conclusion}\n")
        
        # –ß–∞—Å—Ç—å 4: –°–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã
        bibliography_prompt = f"""
–°–æ—Å—Ç–∞–≤—å –°–ü–ò–°–û–ö –õ–ò–¢–ï–†–ê–¢–£–†–´ –¥–ª—è {work_type_names[work_type]} –Ω–∞ —Ç–µ–º—É "{topic}" –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

–í–∫–ª—é—á–∏ 10-15 –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
- –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –∏ –º–æ–Ω–æ–≥—Ä–∞—Ñ–∏–∏
- –£—á–µ–±–Ω—ã–µ –ø–æ—Å–æ–±–∏—è
- –ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
- –ò–Ω—Ç–µ—Ä–Ω–µ—Ç-—Ä–µ—Å—É—Ä—Å—ã (–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)

–§–æ—Ä–º–∞—Ç: –ì–û–°–¢ 7.1-2003
"""
        bibliography = self._make_api_call(system_prompt, bibliography_prompt)
        if not bibliography.startswith("‚ùå"):
            work_parts.append(f"–°–ü–ò–°–û–ö –õ–ò–¢–ï–†–ê–¢–£–†–´\n\n{bibliography}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
        full_work = "\n\n".join(work_parts)
        
        # –ï—Å–ª–∏ –∫–∞–∫–∞—è-—Ç–æ —á–∞—Å—Ç—å –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª–Ω—É—é —Ä–∞–±–æ—Ç—É
        if len(full_work.split()) < self._get_min_word_count(work_type):
            full_prompt = f"""
–ù–∞–ø–∏—à–∏ –ü–û–õ–ù–´–ô –¢–ï–ö–°–¢ {work_type_names[work_type]} –Ω–∞ —Ç–µ–º—É "{topic}" –ø–æ –ø—Ä–µ–¥–º–µ—Ç—É "{subject}".

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∏–ª—å, –∫–∞–∫ –±—É–¥—Ç–æ —Ä–∞–±–æ—Ç—É –ø–∏—à–µ—Ç —Å—Ç—É–¥–µ–Ω—Ç
- –ì–ª—É–±–æ–∫–æ–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∞–Ω–∞–ª–∏–∑
- –õ–æ–≥–∏—á–µ—Å–∫–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
- –û–±—ä–µ–º: {self._get_work_volume(work_type)}
- –ë–µ–∑ –ª–∏—à–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É—é—â–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1. –í–≤–µ–¥–µ–Ω–∏–µ
2. –û—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å (2-3 –≥–ª–∞–≤—ã)
3. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
4. –°–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã

–í–µ—Ä–Ω–∏ —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ (*, <br>, –∏ —Ç.–¥.)
"""
            full_work = self._make_api_call(system_prompt, full_prompt)
        
        return full_work
    
    def _create_detailed_system_prompt(self, work_type, topic, subject, methodic_info):
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç"""
        
        methodic_text = ""
        if methodic_info:
            methodic_text = f"""
–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø –ò–ó –ú–ï–¢–û–î–ò–ß–ö–ò:
{methodic_info.get('requirements', {})}
{methodic_info.get('structure', {})}
"""
        
        return f"""
–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–ø–∏—Å–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫—É—é —Ä–∞–±–æ—Ç—É, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–≥–ª—è–¥–∏—Ç —Ç–∞–∫, –±—É–¥—Ç–æ –µ—ë –Ω–∞–ø–∏—Å–∞–ª —Å—Ç—É–¥–µ–Ω—Ç.

–û–°–ù–û–í–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –ï–°–¢–ï–°–¢–í–ï–ù–ù–´–ô –°–¢–ò–õ–¨ - —Ä–∞–±–æ—Ç–∞ –¥–æ–ª–∂–Ω–∞ –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫, –±—É–¥—Ç–æ –µ—ë –ø–∏—Å–∞–ª —Å—Ç—É–¥–µ–Ω—Ç, –∞ –Ω–µ –ò–ò
2. –ì–õ–£–ë–û–ö–û–ï –†–ê–°–ö–†–´–¢–ò–ï –¢–ï–ú–´ - –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
3. –õ–û–ì–ò–ß–ï–°–ö–ê–Ø –°–¢–†–£–ö–¢–£–†–ê - —á–µ—Ç–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–¥–µ–ª—ã
4. –ê–ö–ê–î–ï–ú–ò–ß–ï–°–ö–ò–ô –Ø–ó–´–ö - –Ω–æ –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–π —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏
5. –ö–û–ù–ö–†–ï–¢–ò–ö–ê - –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –¥–∞–Ω–Ω—ã–µ, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
6. –ß–ò–°–¢–´–ô –¢–ï–ö–°–¢ - –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (*, <br>, –∏ —Ç.–¥.)

–¢–ò–ü –†–ê–ë–û–¢–´: {work_type}
–¢–ï–ú–ê: {topic}
–ü–†–ï–î–ú–ï–¢: {subject}

{methodic_text}

–í–ê–ñ–ù–û: 
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –º–∞—Ä–∫–¥–∞—É–Ω —Ä–∞–∑–º–µ—Ç–∫—É
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π HTML —Ç–µ–≥–∏
- –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –ü–∏—à–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º, —Å–≤—è–∑–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
- –°–æ–±–ª—é–¥–∞–π –ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫—É—é –ª–µ–∫—Å–∏–∫—É, –Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—É—é
"""
    
    def _get_work_volume(self, work_type):
        volumes = {
            "essay": "15-25 —Å—Ç—Ä–∞–Ω–∏—Ü (4000-7000 —Å–ª–æ–≤)",
            "coursework": "30-50 —Å—Ç—Ä–∞–Ω–∏—Ü (8000-12000 —Å–ª–æ–≤)", 
            "thesis": "60-100 —Å—Ç—Ä–∞–Ω–∏—Ü (15000-25000 —Å–ª–æ–≤)"
        }
        return volumes.get(work_type, "20-40 —Å—Ç—Ä–∞–Ω–∏—Ü")
    
    def _get_section_volume(self, work_type, section):
        base_volumes = {
            "essay": {"–≤–≤–µ–¥–µ–Ω–∏–µ": "2-3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã", "–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å": "10-18 —Å—Ç—Ä–∞–Ω–∏—Ü", "–∑–∞–∫–ª—é—á–µ–Ω–∏–µ": "2-3 —Å—Ç—Ä–∞–Ω–∏—Ü—ã"},
            "coursework": {"–≤–≤–µ–¥–µ–Ω–∏–µ": "3-5 —Å—Ç—Ä–∞–Ω–∏—Ü", "–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å": "20-35 —Å—Ç—Ä–∞–Ω–∏—Ü", "–∑–∞–∫–ª—é—á–µ–Ω–∏–µ": "3-5 —Å—Ç—Ä–∞–Ω–∏—Ü"},
            "thesis": {"–≤–≤–µ–¥–µ–Ω–∏–µ": "5-8 —Å—Ç—Ä–∞–Ω–∏—Ü", "–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å": "45-80 —Å—Ç—Ä–∞–Ω–∏—Ü", "–∑–∞–∫–ª—é—á–µ–Ω–∏–µ": "5-8 —Å—Ç—Ä–∞–Ω–∏—Ü"}
        }
        volume_info = base_volumes.get(work_type, {})
        return volume_info.get(section.lower(), "5-10 —Å—Ç—Ä–∞–Ω–∏—Ü")
    
    def _get_min_word_count(self, work_type):
        word_counts = {
            "essay": 4000,
            "coursework": 8000,
            "thesis": 15000
        }
        return word_counts.get(work_type, 5000)
    
    def _make_api_call(self, system_prompt, user_prompt):
        if not self.api_key:
            return "‚ùå –û—à–∏–±–∫–∞: API –∫–ª—é—á DeepSeek –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.8,  # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            "max_tokens": 4000
        }
        
        try:
            logger.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ DeepSeek API: {user_prompt[:100]}...")
            response = requests.post(self.api_url, headers=headers, json=data, timeout=120)
            response.raise_for_status()
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            word_count = len(content.split())
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: {word_count} —Å–ª–æ–≤")
            
            return content
            
        except requests.exceptions.Timeout:
            return "‚è∞ –í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑."
        except requests.exceptions.RequestException as e:
            logger.error(f"API error: {e}")
            return "‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å —Å–µ—Ä–≤–∏—Å–æ–º."
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {str(e)}"

class CourseworkBot:
    def __init__(self):
        self.db = Database()
        self.doc_processor = DocumentProcessor()
        self.writer = AcademicWriter()
        self.doc_generator = TextDocumentGenerator()
        self.user_sessions = {}
    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user = update.effective_user
        self.db.add_user(user.id, user.username, user.first_name, user.last_name)
        
        welcome_text = f"""üéì <b>–ê–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫</b>

–ü—Ä–∏–≤–µ—Ç, {user.first_name}! –Ø –Ω–∞–ø–∏—à—É –¥–ª—è —Ç–µ–±—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫—É—é —Ä–∞–±–æ—Ç—É, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ.

–í—ã–±–µ—Ä–∏ —Ç–∏–ø —Ä–∞–±–æ—Ç—ã:"""

        keyboard = [
            [InlineKeyboardButton("üìö –ö—É—Ä—Å–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞", callback_data="work_coursework")],
            [InlineKeyboardButton("üìù –†–µ—Ñ–µ—Ä–∞—Ç", callback_data="work_essay")],
            [InlineKeyboardButton("üéì –î–∏–ø–ª–æ–º–Ω–∞—è —Ä–∞–±–æ—Ç–∞", callback_data="work_thesis")],
            [InlineKeyboardButton("üìÑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–æ–¥–∏—á–∫—É", callback_data="upload_methodic")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await update.message.reply_text(welcome_text, reply_markup=reply_markup, parse_mode='HTML')
    
    async def handle_button(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        data = query.data
        
        if data.startswith('work_'):
            work_type = data.split('_')[1]
            self.user_sessions[user_id] = {
                'work_type': work_type,
                'stage': 'subject'
            }
            
            work_names = {
                'coursework': '–∫—É—Ä—Å–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã',
                'essay': '—Ä–µ—Ñ–µ—Ä–∞—Ç–∞',
                'thesis': '–¥–∏–ø–ª–æ–º–Ω–æ–π —Ä–∞–±–æ—Ç—ã'
            }
            
            await query.edit_message_text(
                f"üìù –í—ã–±—Ä–∞–Ω —Ç–∏–ø: <b>{work_names[work_type]}</b>\n\n–í–≤–µ–¥–∏—Ç–µ –ø—Ä–µ–¥–º–µ—Ç –∏–ª–∏ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—É:",
                parse_mode='HTML'
            )
        
        elif data == 'upload_methodic':
            await query.edit_message_text(
                "üìé –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Ñ–∞–π–ª –º–µ—Ç–æ–¥–∏—á–∫–∏ (PDF, DOCX, TXT):\n\n"
                "–ú–µ—Ç–æ–¥–∏—á–∫–∞ –ø–æ–º–æ–∂–µ—Ç —É—á–µ—Å—Ç—å –æ—Å–æ–±—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞—à–µ–≥–æ —É—á–µ–±–Ω–æ–≥–æ –∑–∞–≤–µ–¥–µ–Ω–∏—è."
            )
    
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        user_message = update.message.text.strip()
        
        session = self.user_sessions.get(user_id, {})
        
        if not session:
            await update.message.reply_text("ü§î –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏—Ç–µ —Å –∫–æ–º–∞–Ω–¥—ã /start")
            return
        
        current_stage = session.get('stage')
        
        if current_stage == 'subject':
            # –ü–æ–ª—É—á–∏–ª–∏ –ø—Ä–µ–¥–º–µ—Ç, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–µ–º—É
            session['subject'] = user_message
            session['stage'] = 'topic'
            self.user_sessions[user_id] = session
            
            await update.message.reply_text(
                f"üìö –ü—Ä–µ–¥–º–µ—Ç: <b>{user_message}</b>\n\n–¢–µ–ø–µ—Ä—å –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É —Ä–∞–±–æ—Ç—ã:",
                parse_mode='HTML'
            )
        
        elif current_stage == 'topic':
            # –ü–æ–ª—É—á–∏–ª–∏ —Ç–µ–º—É, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥–∏—á–∫—É
            session['topic'] = user_message
            session['stage'] = 'methodic_choice'
            self.user_sessions[user_id] = session
            
            methodics = self.db.get_methodics()
            if methodics:
                keyboard = []
                for methodic_id, filename in methodics:
                    display_name = filename[:25] + "..." if len(filename) > 25 else filename
                    keyboard.append([InlineKeyboardButton(f"üìÑ {display_name}", callback_data=f"methodic_{methodic_id}")])
                keyboard.append([InlineKeyboardButton("üö´ –ë–µ–∑ –º–µ—Ç–æ–¥–∏—á–∫–∏", callback_data="no_methodic")])
                
                reply_markup = InlineKeyboardMarkup(keyboard)
                await update.message.reply_text(
                    f"üéØ –¢–µ–º–∞: <b>{user_message}</b>\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥–∏—á–∫—É –¥–ª—è —É—á–µ—Ç–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π:",
                    reply_markup=reply_markup,
                    parse_mode='HTML'
                )
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–æ–¥–∏—á–µ–∫, —Å—Ä–∞–∑—É –Ω–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                await self.start_work_generation(update, session, None)
    
    async def start_work_generation(self, update, session, methodic_info):
        """–ù–∞—á–∏–Ω–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã"""
        user_id = update.effective_user.id if hasattr(update, 'effective_user') else update.from_user.id
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å –≤ –ë–î
        work_id = self.db.create_work(
            user_id=user_id,
            work_type=session['work_type'],
            topic=session['topic'],
            subject=session['subject'],
            methodic_info=methodic_info
        )
        session['work_id'] = work_id
        self.user_sessions[user_id] = session
        
        # –°—Ä–∞–∑—É –Ω–∞—á–∏–Ω–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –ø–æ–ª–Ω–æ–π —Ä–∞–±–æ—Ç—ã
        await self.generate_complete_work(update, session)
    
    async def generate_complete_work(self, update, session):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é —Ä–∞–±–æ—Ç—É –∏ —Å–æ–∑–¥–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç"""
        message_obj = update.message if hasattr(update, 'message') else update
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        progress_msg = await message_obj.reply_text(
            "üîÑ <b>–ù–∞—á–∏–Ω–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã...</b>\n\n"
            "üìù –ü–∏—à—É –≤–≤–µ–¥–µ–Ω–∏–µ...\n"
            "‚è≥ –≠—Ç–æ –∑–∞–π–º–µ—Ç 5-7 –º–∏–Ω—É—Ç\n"
            "‚ú® –†–∞–±–æ—Ç–∞ –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ",
            parse_mode='HTML'
        )
        
        methodic_info = session.get('methodic_info', {})
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Ä–∞–±–æ—Ç—É
        full_content = self.writer.generate_complete_work(
            work_type=session['work_type'],
            topic=session['topic'],
            subject=session['subject'],
            methodic_info=methodic_info
        )
        
        if full_content.startswith("‚ùå") or full_content.startswith("‚è∞"):
            await progress_msg.edit_text(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–∞–±–æ—Ç—É: {full_content}")
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–º —Ä–∞–±–æ—Ç—ã
        word_count = len(full_content.split())
        expected_min = self.writer._get_min_word_count(session['work_type'])
        
        if word_count < expected_min * 0.7:  # –ï—Å–ª–∏ –æ–±—ä–µ–º –º–µ–Ω—å—à–µ 70% –æ—Ç –æ–∂–∏–¥–∞–µ–º–æ–≥–æ
            await progress_msg.edit_text(
                "‚ö†Ô∏è <b>–û–±—ä–µ–º —Ä–∞–±–æ—Ç—ã –º–µ–Ω—å—à–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ. –î–æ–ø–∏—Å—ã–≤–∞—é...</b>",
                parse_mode='HTML'
            )
            # –ü—Ä–æ–±—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç—å —Ä–∞–±–æ—Ç—É
            additional_content = self.writer._make_api_call(
                "–î–æ–ø–æ–ª–Ω–∏ —Ä–∞–±–æ—Ç—É, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏—Ç—å –æ–±—ä–µ–º –∏ –≥–ª—É–±–∏–Ω—É –∞–Ω–∞–ª–∏–∑–∞.",
                f"–î–æ–ø–æ–ª–Ω–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç, —É–≤–µ–ª–∏—á–∏–≤ –æ–±—ä–µ–º –¥–æ {expected_min} —Å–ª–æ–≤: {full_content[:1000]}..."
            )
            if not additional_content.startswith("‚ùå"):
                full_content += "\n\n" + additional_content
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –ë–î
        self.db.update_work_content(session['work_id'], full_content)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
        user_info = f"{message_obj.from_user.first_name} {message_obj.from_user.last_name or ''}".strip()
        
        doc_stream = self.doc_generator.create_document(
            work_type=session['work_type'],
            topic=session['topic'],
            subject=session['subject'],
            content=full_content,
            methodic_info=methodic_info,
            user_info=user_info
        )
        
        if not doc_stream:
            await progress_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
            return
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        work_names = {
            'coursework': '–ö—É—Ä—Å–æ–≤–∞—è —Ä–∞–±–æ—Ç–∞',
            'essay': '–†–µ—Ñ–µ—Ä–∞—Ç', 
            'thesis': '–î–∏–ø–ª–æ–º–Ω–∞—è —Ä–∞–±–æ—Ç–∞'
        }
        
        filename = f"{work_names[session['work_type']]} - {session['topic'][:30]}.txt"
        word_count = len(full_content.split())
        
        await message_obj.reply_document(
            document=doc_stream,
            filename=filename,
            caption=(
                f"üéâ <b>{work_names[session['work_type']]} –ì–û–¢–û–í–ê!</b>\n\n"
                f"üìö –¢–µ–º–∞: {session['topic']}\n"
                f"üî¨ –ü—Ä–µ–¥–º–µ—Ç: {session['subject']}\n"
                f"üìÑ –û–±—ä–µ–º: {word_count} —Å–ª–æ–≤\n"
                f"üé® –°—Ç–∏–ª—å: –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏–π\n"
                f"‚úÖ –ö–∞—á–µ—Å—Ç–≤–æ: –ø–æ–ª–Ω–æ–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã\n\n"
                f"<i>–î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!</i>"
            ),
            parse_mode='HTML'
        )
        
        await progress_msg.delete()
        
        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Ä–∞–±–æ—Ç—É
        keyboard = [
            [InlineKeyboardButton("üîÑ –ù–∞–ø–∏—Å–∞—Ç—å –Ω–æ–≤—É—é —Ä–∞–±–æ—Ç—É", callback_data="new_work")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        await message_obj.reply_text(
            "‚ú® <b>–†–∞–±–æ—Ç–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!</b>\n\n"
            f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {word_count} —Å–ª–æ–≤, –ø–æ–ª–Ω–æ–µ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ —Ç–µ–º—ã\n"
            "üéØ –ö–∞—á–µ—Å—Ç–≤–æ: —Ä–∞–±–æ—Ç–∞ –≤—ã–≥–ª—è–¥–∏—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ\n\n"
            "–í—ã –º–æ–∂–µ—Ç–µ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—É—é —Ä–∞–±–æ—Ç—É:",
            reply_markup=reply_markup,
            parse_mode='HTML'
        )
    
    async def handle_methodic_selection(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ –º–µ—Ç–æ–¥–∏—á–∫–∏"""
        query = update.callback_query
        await query.answer()
        
        user_id = query.from_user.id
        data = query.data
        
        session = self.user_sessions.get(user_id, {})
        
        if data == 'no_methodic':
            session['methodic_info'] = None
            self.user_sessions[user_id] = session
            await self.start_work_generation(query, session, None)
        elif data.startswith('methodic_'):
            methodic_id = int(data.split('_')[1])
            methodic_data = self.db.get_methodic(methodic_id)
            if methodic_data:
                methodic_info = {
                    'requirements': json.loads(methodic_data[3]) if methodic_data[3] else {},
                    'structure': json.loads(methodic_data[4]) if methodic_data[4] else {},
                }
                session['methodic_info'] = methodic_info
                session['methodic_id'] = methodic_id
                self.user_sessions[user_id] = session
                await self.start_work_generation(query, session, methodic_info)
            else:
                await query.message.reply_text("‚ùå –ú–µ—Ç–æ–¥–∏—á–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–æ–¥–∏—á–µ–∫"""
        user_id = update.effective_user.id
        
        try:
            document = update.message.document
            filename = document.file_name
            file_extension = filename.lower().split('.')[-1]
            
            allowed_extensions = ['pdf', 'docx', 'txt']
            if file_extension not in allowed_extensions:
                await update.message.reply_text("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF, DOCX, TXT —Ñ–∞–π–ª—ã")
                return
            
            file = await context.bot.get_file(document.file_id)
            file_path = os.path.join("–º–µ—Ç–æ–¥–∏—á–∫–∏", filename)
            await file.download_to_drive(file_path)
            
            processing_msg = await update.message.reply_text("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –º–µ—Ç–æ–¥–∏—á–∫—É...")
            
            methodic_info = await self.doc_processor.process_methodic(file_path)
            
            if not methodic_info:
                await processing_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–µ—Ç–æ–¥–∏—á–∫—É")
                return
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–æ–¥–∏—á–∫—É –≤ –ë–î
            methodic_id = self.db.add_methodic(
                filename=filename,
                file_path=file_path,
                requirements=json.dumps(methodic_info['requirements']),
                structure=json.dumps(methodic_info['structure']),
                formatting=json.dumps(methodic_info),
                user_id=user_id
            )
            
            await processing_msg.edit_text(
                f"‚úÖ –ú–µ—Ç–æ–¥–∏—á–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\n"
                f"üìã –£—á—Ç–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫:\n"
                f"‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–µ —Ä–∞–±–æ—Ç—ã\n"
                f"‚Ä¢ –û–±—ä–µ–º—É –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é\n"
                f"‚Ä¢ –û—Ñ–æ—Ä–º–ª–µ–Ω–∏—é\n\n"
                f"–¢–µ–ø–µ—Ä—å –Ω–∞—á–Ω–∏—Ç–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ /start"
            )
            
        except Exception as e:
            logger.error(f"Upload error: {e}")
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞")
    
    async def handle_new_work(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–∫–∏ –Ω–æ–≤–æ–π —Ä–∞–±–æ—Ç—ã"""
        query = update.callback_query
        await query.answer()
        
        # –û—á–∏—â–∞–µ–º —Å–µ—Å—Å–∏—é –∏ –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ
        user_id = query.from_user.id
        if user_id in self.user_sessions:
            del self.user_sessions[user_id]
        
        await self.start(query, context)
    
    async def error_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        logger.error(f"Error: {context.error}")
        
        try:
            if update and hasattr(update, 'effective_chat'):
                await context.bot.send_message(
                    chat_id=update.effective_chat.id,
                    text="‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ –∏–ª–∏ –Ω–∞—á–Ω–∏—Ç–µ —Å /start"
                )
        except Exception as e:
            logger.error(f"Error in error handler: {e}")
    
    def run(self):
        if not BOT_TOKEN:
            logger.error("‚ùå BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
        
        if not DEEPSEEK_API_KEY:
            logger.warning("‚ö†Ô∏è DEEPSEEK_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω! –ë–æ—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏.")
        
        application = Application.builder().token(BOT_TOKEN).build()
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
        application.add_handler(CommandHandler("start", self.start))
        application.add_handler(CallbackQueryHandler(self.handle_button, pattern="^(work_|upload_methodic)"))
        application.add_handler(CallbackQueryHandler(self.handle_methodic_selection, pattern="^(methodic_|no_methodic)"))
        application.add_handler(CallbackQueryHandler(self.handle_new_work, pattern="^new_work$"))
        application.add_handler(MessageHandler(filters.Document.ALL, self.handle_document))
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text))
        application.add_error_handler(self.error_handler)
        
        logger.info("ü§ñ –£–ª—É—á—à–µ–Ω–Ω—ã–π –±–æ—Ç-–ø–∏—Å–∞—Ç–µ–ª—å –∑–∞–ø—É—â–µ–Ω!")
        print("=" * 60)
        print("üéì Quality Academic Writer Bot Started!")
        print("üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç —Å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º")
        print("‚ö° –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –æ–±—ä–µ–º –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–∞")
        print("üé® –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤")
        print("=" * 60)
        
        application.run_polling()

if __name__ == "__main__":
    bot = CourseworkBot()
    bot.run()